{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I'll do my best to explain the process of learning the sensitivity image usign a (very) simple residual CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# first let's get our imports sorted\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import sirf.STIR as stir\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "dir_path = os.path.dirname(os.getcwd())\n",
    "source_path = os.path.join(dir_path, 'source')\n",
    "sys.path.append(source_path)\n",
    "\n",
    "from data.ellipses import EllipsesDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First, let's get some template data\n",
    "data_path = os.path.join(dir_path, 'data', 'template_data')\n",
    "emission_image = stir.ImageData(os.path.join(data_path, 'emission.hv'))\n",
    "attenuation_image = stir.ImageData(os.path.join(data_path, 'attenuation.hv'))\n",
    "template_sinogram = stir.AcquisitionData(os.path.join(data_path, 'template_sinogram.hs'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_samples = 32\n",
    "batch_size = 8\n",
    "\n",
    "dataloader = torch.utils.data.DataLoader(\n",
    "    EllipsesDataset(attenuation_image, template_sinogram,  \n",
    "                    num_samples=num_samples, generate_non_attenuated_sensitivity=False),\n",
    "                    batch_size=batch_size, shuffle=True)\n",
    "\n",
    "X_train = []\n",
    "y_train = []\n",
    "for train in dataloader:\n",
    "    X, y = train\n",
    "    X_train.append(X)\n",
    "    y_train.append(y)\n",
    "\n",
    "X_train, y_train = torch.cat(X_train, dim=0), torch.cat(y_train, dim=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class UltraSimpleResNet(nn.Module):\n",
    "    def __init__(self, in_channels=2, out_channels=1):\n",
    "        super(UltraSimpleResNet, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels, 64, kernel_size=3, stride=1, padding=1)\n",
    "        self.conv2 = nn.Conv2d(64, 64, kernel_size=3, stride=1, padding=1)\n",
    "        self.conv3 = nn.Conv2d(64, 64, kernel_size=3, stride=1, padding=1)\n",
    "        self.conv4 = nn.Conv2d(64, out_channels, kernel_size=3, stride=1, padding=1)\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.conv2(x) + x\n",
    "        x = self.relu(x)\n",
    "        x = self.conv3(x)+ x\n",
    "        x = self.relu(x)\n",
    "        x = self.conv4(x)\n",
    "        return x\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = UltraSimpleResNet(in_channels=2, out_channels=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# lets see what we get from the untrained model\n",
    "\n",
    "out = model(X_train[0].to(device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(out[0].detach().cpu().numpy())\n",
    "plt.title('Untrained model output')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# unsurpsingly, it's just a load of rubbish\n",
    "# Let's see if we can train it to do something useful\n",
    "\n",
    "def train_epoch(model, dataloader, loss_fn, optimizer, device):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    for inputs, targets in dataloader:\n",
    "        inputs, targets = inputs.to(device), targets.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = loss_fn(outputs, targets)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "    return total_loss / len(dataloader)\n",
    "\n",
    "train_loader = DataLoader(TensorDataset(X_train, y_train), batch_size=batch_size, shuffle=True)\n",
    "\n",
    "train_loss = []\n",
    "for epoch in range(10):\n",
    "    loss = train_epoch(model, train_loader, nn.MSELoss(), torch.optim.Adam(model.parameters(), lr=0.001), device)\n",
    "    train_loss.append(loss)\n",
    "    print(f'Epoch {epoch} - Loss: {loss}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(train_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's see what we get from the trained model\n",
    "out = model(X_train[0].to(device))\n",
    "plt.imshow(out[0].detach().cpu().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# and we've got something that looks a little bit more sensible!!!\n",
    "# Let's compare it to the ground truth\n",
    "fig, ax = plt.subplots(1, 3)\n",
    "ax[0].imshow(out[0].detach().cpu().numpy())\n",
    "ax[0].set_title('Model output')\n",
    "ax[1].imshow(y_train[0].detach().cpu().numpy())\n",
    "ax[1].set_title('Ground truth')\n",
    "ax[2].imshow((X_train[0][0]).detach().cpu().numpy())\n",
    "ax[2].set_title('Input sensitivity')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We're still a long way off (it looks much more like the input sensitivity) but we can see that something is happening!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython"
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
