{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I'll do my best to explain the process of learning the sensitivity image usign a (very) simple residual CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# first let's get our imports sorted\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import sirf.STIR as stir\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "dir_path = os.path.dirname(os.getcwd())\n",
    "source_path = os.path.join(dir_path, 'source')\n",
    "sys.path.append(source_path)\n",
    "\n",
    "from data.ellipses import EllipsesDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First, let's get some template data\n",
    "data_path = os.path.join(dir_path, 'data', 'template_data')\n",
    "emission_image = stir.ImageData(os.path.join(data_path, 'emission.hv'))\n",
    "attenuation_image = stir.ImageData(os.path.join(data_path, 'attenuation.hv'))\n",
    "template_sinogram = stir.AcquisitionData(os.path.join(data_path, 'template_sinogram.hs'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_samples = 128\n",
    "batch_size = 16\n",
    "\n",
    "if os.path.exists(os.path.join(data_path, f'X_train_n{num_samples}.pt')) and os.path.exists(os.path.join(data_path, f'y_train_n{num_samples}.pt')):\n",
    "    X_train = torch.load(os.path.join(data_path, f'X_train_n{num_samples}.pt'))\n",
    "    y_train = torch.load(os.path.join(data_path, f'y_train_n{num_samples}.pt'))\n",
    "\n",
    "else:\n",
    "    dataloader = torch.utils.data.DataLoader(\n",
    "        EllipsesDataset(attenuation_image, template_sinogram,  \n",
    "                        num_samples=num_samples, generate_non_attenuated_sensitivity=False),\n",
    "                        batch_size=batch_size, shuffle=True)\n",
    "\n",
    "    X_train = []\n",
    "    y_train = []\n",
    "    for train in dataloader:\n",
    "        X, y = train\n",
    "        X_train.append(X)\n",
    "        y_train.append(y)\n",
    "\n",
    "    X_train, y_train = torch.cat(X_train, dim=0), torch.cat(y_train, dim=0)\n",
    "\n",
    "    # save the data\n",
    "    torch.save(X_train, os.path.join(data_path, f'X_train_n{num_samples}.pt'))\n",
    "    torch.save(y_train, os.path.join(data_path, f'y_train_n{num_samples}.pt'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleSkipCNN(nn.Module):\n",
    "    def __init__(self, in_channels=2, out_channels=1, device='cpu'):\n",
    "        super(SimpleSkipCNN, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels, 64, kernel_size=3, stride=1, padding=1)\n",
    "        self.conv2 = nn.Conv2d(64, 64, kernel_size=3, stride=1, padding=1)\n",
    "        self.conv3 = nn.Conv2d(64, 64, kernel_size=3, stride=1, padding=1)\n",
    "        self.conv4 = nn.Conv2d(64, out_channels, kernel_size=3, stride=1, padding=1)\n",
    "        self.relu = nn.LeakyReLU(0.2)\n",
    "        \n",
    "        # Learnable weights for skip connections\n",
    "        self.skip_weight1 = nn.Parameter(torch.ones(1).to(device)) # Weight for the first skip connection\n",
    "        self.skip_weight2 = nn.Parameter(torch.ones(1).to(device))  # Weight for the second skip connection\n",
    "\n",
    "    def forward(self, x):\n",
    "        x1 = self.conv1(x)\n",
    "        x = self.relu(x1)\n",
    "        \n",
    "        x = self.conv2(x) + self.skip_weight1 * x1\n",
    "        x = self.relu(x)\n",
    "        \n",
    "        x2 = x + x1\n",
    "        x = self.conv3(x) + self.skip_weight2 * x2  # Apply learned weight to the second skip connection\n",
    "        x = self.relu(x)\n",
    "        \n",
    "        x = self.conv4(x)  # No skip connection here as we're reducing to output channels\n",
    "        \n",
    "        return nn.ReLU()(x) # ReLU activation on the output to ensure non-negativity\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "model = SimpleSkipCNN(in_channels=2, out_channels=1, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lets see what we get from the untrained model\n",
    "\n",
    "out = model(X_train[0].to(device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(out[0].detach().cpu().numpy())\n",
    "plt.title('Untrained model output')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# unsurpsingly, it's just a load of rubbish\n",
    "# Let's see if we can train it to do something useful\n",
    "\n",
    "def train_epoch(model, dataloader, loss_fn, optimizer, device):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    for inputs, targets in dataloader:\n",
    "        inputs, targets = inputs.to(device), targets.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = loss_fn(outputs, targets)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "    return total_loss / len(dataloader)\n",
    "\n",
    "train_loader = DataLoader(TensorDataset(X_train, y_train), batch_size=batch_size, shuffle=True)\n",
    "\n",
    "train_loss = []\n",
    "for epoch in range(50):\n",
    "    loss = train_epoch(model, train_loader, nn.MSELoss(), torch.optim.Adam(model.parameters(), lr=0.001), device)\n",
    "    train_loss.append(loss)\n",
    "    print(f'Epoch {epoch} - Loss: {loss}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(train_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's generate some test data - just ellipses for now\n",
    "test_data = EllipsesDataset(attenuation_image, template_sinogram, num_samples=8, generate_non_attenuated_sensitivity=False)\n",
    "test_loader = DataLoader(test_data, batch_size=1, shuffle=True)\n",
    "\n",
    "# let's see how the model does on the test data\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    for i, (X, y) in enumerate(test_loader):\n",
    "        X, y = X.to(device), y.to(device)\n",
    "        vmax = max([X[0, 0].max(), y[0].max()])\n",
    "        out = model(X)\n",
    "        plt.figure(figsize=(8, 2))\n",
    "        plt.subplot(1, 3, 1)\n",
    "        plt.imshow(X[0, 0].detach().cpu().numpy(), vmax=vmax)\n",
    "        plt.title('Input')\n",
    "        plt.subplot(1, 3, 2)\n",
    "        plt.imshow(out[0].detach().cpu().numpy()[0], vmax=vmax)\n",
    "        plt.title('Model output')\n",
    "        plt.subplot(1, 3, 3)\n",
    "        plt.imshow(y[0].detach().cpu().numpy(), vmax=vmax)\n",
    "        plt.title('Ground truth')\n",
    "        # no ticks\n",
    "        plt.xticks([])\n",
    "        plt.yticks([])\n",
    "        # colorbar\n",
    "        plt.colorbar()\n",
    "        if i > 5:\n",
    "            break\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We're still a long way off but we can see that something is happening!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below is a little bit of code to do with estimating the importance of different part sof your image to the model. It's not entirely necessary - more me experimenting a little"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a dummy input tensor (2 channels, 155x155 pixels)\n",
    "input_tensor = X.requires_grad_() # using last input from the test data\n",
    "\n",
    "# Forward pass to compute the output\n",
    "output = model(input_tensor.to(device))\n",
    "\n",
    "# Select a target for which to compute gradients\n",
    "# Here, we simply take the mean of the output as a representative target\n",
    "target = output.mean()\n",
    "\n",
    "# Compute gradients of the target with respect to input\n",
    "target.backward()\n",
    "\n",
    "# Compute the saliency map as the absolute value of the gradient\n",
    "saliency_map = input_tensor.grad.data.abs().squeeze().sum(0)  # Sum the gradients across the channels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def relu_backward_hook_function(module, grad_in, grad_out):\n",
    "    \"\"\"\n",
    "    If there is a negative gradient, changes it to zero.\n",
    "    \"\"\"\n",
    "    # grad_in contains the gradient with respect to the input of the ReLU\n",
    "    # grad_out contains the gradient with respect to the output of the ReLU\n",
    "    if isinstance(module, nn.ReLU):\n",
    "        return (torch.clamp(grad_in[0], min=0.0),)\n",
    "\n",
    "# 2. Register the hook for all ReLU layers in the model\n",
    "def register_hooks(model):\n",
    "    \"\"\"\n",
    "    Registers the backward hook for all ReLU layers in the model.\n",
    "    \"\"\"\n",
    "    for module in model.modules():\n",
    "        if isinstance(module, nn.ReLU):\n",
    "            module.register_backward_hook(relu_backward_hook_function)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "register_hooks(model)\n",
    "model.eval()  # Set the model to evaluation mode\n",
    "\n",
    "# Forward pass\n",
    "output = model(input_tensor.to(device))\n",
    "\n",
    "# Define a target for the backward pass, for example, the mean of the output\n",
    "target = output.mean()\n",
    "\n",
    "# Backward pass\n",
    "target.backward()\n",
    "\n",
    "# 4. Extract the gradients\n",
    "# The gradients of the input with respect to the target are now modified by guided backpropagation\n",
    "gradients = input_tensor.grad.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# show both gradients\n",
    "fig, ax = plt.subplots(1, 2)\n",
    "ax[0].imshow(saliency_map.cpu().numpy(), cmap='hot')\n",
    "ax[0].set_title('Saliency Map')\n",
    "ax[1].imshow(gradients.squeeze().sum(0).cpu().numpy(), cmap='hot')\n",
    "ax[1].set_title('Guided Backpropagation')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython"
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
